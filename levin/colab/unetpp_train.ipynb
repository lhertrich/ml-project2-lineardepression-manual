{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6AZcctE19pK",
        "outputId": "9ac1c863-0c0d-40d8-823a-5ac48d5e2f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "n-j1g9-y2B7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_path = '/content/drive/My Drive/ML project 2/'\n",
        "sys.path.append(project_path)"
      ],
      "metadata": {
        "id": "jAY2H-wI2DkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U segmentation-models-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdS-hggJ4bxl",
        "outputId": "593c6dd0-0067-4e4b-e49c-7f49e92b9dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: segmentation-models-pytorch in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.7.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.6 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.26.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (11.0.0)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.7.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (1.17.0)\n",
            "Requirement already satisfied: timm==0.9.7 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.9.7)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.5.1+cu121)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (4.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.26.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "import json\n",
        "from levin.train_evaluate import TrainAndEvaluate\n",
        "from levin.models.unetpp.unetpp_dataset import UnetPlusPlusRoadSegmentationDataset\n",
        "from levin.models.unetpp.unetpp import UnetPlusPlus\n",
        "from levin.loss_functions import ComboLoss, DiceLoss, TverskyLoss, WeightedBCEWithLogitsLoss\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "wo52V2Hw2Fur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = os.path.join(project_path, \"data\", \"training\", \"augmented\", \"images\")\n",
        "mask_dir = os.path.join(project_path, \"data\", \"training\", \"augmented\", \"masks\")\n",
        "\n",
        "external_image_dir = os.path.join(project_path, \"data\", \"training\", \"complete_data_augmented\", \"images\")\n",
        "external_mask_dir = os.path.join(project_path, \"data\", \"training\", \"complete_data_augmented\", \"masks\")\n",
        "\n",
        "chicago_image_dir = os.path.join(project_path, \"data\", \"training\", \"chicago_data_augmented\", \"images\")\n",
        "chicago_mask_dir = os.path.join(project_path, \"data\", \"training\", \"chicago_data_augmented\", \"masks\")"
      ],
      "metadata": {
        "id": "zWXcuXVJ2gD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load files for original augmented, external images and chicago images\n",
        "image_filenames = sorted(os.listdir(image_dir))\n",
        "mask_filenames = sorted(os.listdir(mask_dir))\n",
        "\n",
        "external_image_filenames = sorted(os.listdir(external_image_dir))\n",
        "external_mask_filenames = sorted(os.listdir(external_mask_dir))\n",
        "\n",
        "chicago_image_filenames = sorted(os.listdir(chicago_image_dir))\n",
        "chicago_mask_filenames = sorted(os.listdir(chicago_mask_dir))"
      ],
      "metadata": {
        "id": "3FoYLQU92iGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_name=\"resnet50\"\n",
        "encoder_weight=\"imagenet\""
      ],
      "metadata": {
        "id": "-g6KYkFN3Kea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Original augmented data\n",
        "# Create train test and validation set for original augmented data\n",
        "train_images, test_images, train_masks, test_masks = train_test_split(\n",
        "    image_filenames, mask_filenames, test_size=0.2, random_state=42\n",
        ")\n",
        "train_images, validation_images, train_masks, validation_masks = train_test_split(\n",
        "    train_images, train_masks, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Number of training images: {len(train_images)}\")\n",
        "print(f\"Number of validation images: {len(validation_images)}\")\n",
        "print(f\"Number of test images: {len(test_images)}\")\n",
        "\n",
        "# Define datasets for train and test sets\n",
        "train_dataset = UnetPlusPlusRoadSegmentationDataset(image_dir, mask_dir, train_images, train_masks, encoder_name, encoder_weight)\n",
        "test_dataset = UnetPlusPlusRoadSegmentationDataset(image_dir, mask_dir, test_images, test_masks, encoder_name, encoder_weight)\n",
        "validation_dataset = UnetPlusPlusRoadSegmentationDataset(image_dir, mask_dir, validation_images, validation_masks, encoder_name, encoder_weight)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "### Complete augmented original and external data\n",
        "# Create train test and validation set for external data\n",
        "external_train_images, external_test_images, external_train_masks, external_test_masks = train_test_split(\n",
        "    external_image_filenames, external_mask_filenames, test_size=0.2, random_state=42\n",
        ")\n",
        "external_train_images, external_validation_images, external_train_masks, external_validation_masks = train_test_split(\n",
        "    external_train_images, external_train_masks, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Number of external training images: {len(external_train_images)}\")\n",
        "print(f\"Number of external validation images: {len(external_validation_images)}\")\n",
        "print(f\"Number of external test images: {len(external_test_images)}\")\n",
        "\n",
        "# Define datasets for train and test sets\n",
        "external_train_dataset = UnetPlusPlusRoadSegmentationDataset(external_image_dir, external_mask_dir, external_train_images, external_train_masks, encoder_name, encoder_weight)\n",
        "external_test_dataset = UnetPlusPlusRoadSegmentationDataset(external_image_dir, external_mask_dir, external_test_images, external_test_masks, encoder_name, encoder_weight)\n",
        "external_validation_dataset = UnetPlusPlusRoadSegmentationDataset(external_image_dir, external_mask_dir, external_validation_images, external_validation_masks, encoder_name, encoder_weight)\n",
        "\n",
        "external_train_loader = DataLoader(external_train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "external_test_loader = DataLoader(external_test_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "external_validation_loader = DataLoader(external_validation_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "### Augmented original and chicago data\n",
        "# Create train test and validation set for external chicago data\n",
        "chicago_train_images, chicago_test_images, chicago_train_masks, chicago_test_masks = train_test_split(\n",
        "    chicago_image_filenames, chicago_mask_filenames, test_size=0.2, random_state=42\n",
        ")\n",
        "chicago_train_images, chicago_validation_images, chicago_train_masks, chicago_validation_masks = train_test_split(\n",
        "    chicago_train_images, chicago_train_masks, test_size=0.1, random_state=42)\n",
        "\n",
        "print(f\"Number of chicago training images: {len(chicago_train_images)}\")\n",
        "print(f\"Number of chicago validation images: {len(chicago_validation_images)}\")\n",
        "print(f\"Number of chicago test images: {len(chicago_test_images)}\")\n",
        "\n",
        "# Define datasets for train and test sets\n",
        "chicago_train_dataset = UnetPlusPlusRoadSegmentationDataset(chicago_image_dir, chicago_mask_dir, chicago_train_images, chicago_train_masks, encoder_name, encoder_weight)\n",
        "chicago_test_dataset = UnetPlusPlusRoadSegmentationDataset(chicago_image_dir, chicago_mask_dir, chicago_test_images, chicago_test_masks, encoder_name, encoder_weight)\n",
        "chicago_validation_dataset = UnetPlusPlusRoadSegmentationDataset(chicago_image_dir, chicago_mask_dir, chicago_validation_images, external_validation_masks, encoder_name, encoder_weight)\n",
        "\n",
        "chicago_train_loader = DataLoader(chicago_train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "chicago_test_loader = DataLoader(chicago_test_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
        "chicago_validation_loader = DataLoader(chicago_validation_dataset, batch_size=8, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vMyDCuu2lOj",
        "outputId": "6ad8e5c8-a011-44f9-acd5-08f157e31bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training images: 360\n",
            "Number of validation images: 40\n",
            "Number of test images: 100\n",
            "Number of external training images: 6235\n",
            "Number of external validation images: 693\n",
            "Number of external test images: 1732\n",
            "Number of chicago training images: 2005\n",
            "Number of chicago validation images: 223\n",
            "Number of chicago test images: 557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test different loss functions for original augmented data\n",
        "root_path = os.path.join(project_path, \"levin\")\n",
        "save_path = os.path.join(root_path, \"trained_models\", \"unet++\")\n",
        "print(f\"Created save path {save_path}\")\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "loss_functions = [torch.nn.BCEWithLogitsLoss(), WeightedBCEWithLogitsLoss(), DiceLoss(), ComboLoss(), TverskyLoss()]\n",
        "best_f1 = 0\n",
        "best_threshold = 0\n",
        "best_epoch = 0\n",
        "best_loss_function = None\n",
        "best_data = \"original\"\n",
        "for criterion in loss_functions:\n",
        "  print(f\"Training model with {criterion.__class__.__name__}\")\n",
        "  # Train and evaluate\n",
        "  model = UnetPlusPlus(encoder_name=encoder_name, encoder_weight=encoder_weight, in_channels=3, num_labels=1)\n",
        "  train_eval = TrainAndEvaluate(model, train_loader, validation_loader, test_loader, criterion, 10, save_path, save=False)\n",
        "  f1, threshold, epoch = train_eval.run()\n",
        "  if f1 > best_f1:\n",
        "    best_f1 = f1\n",
        "    best_threshold = threshold\n",
        "    best_epoch = epoch\n",
        "    best_loss_function = criterion\n",
        "\n",
        "print(f\"Best F1 score: {best_f1}\")\n",
        "print(f\"Best threshold: {best_threshold}\")\n",
        "print(f\"Best epoch: {best_epoch}\")\n",
        "print(f\"Best loss function: {best_loss_function.__class__.__name__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe5y1lDE251j",
        "outputId": "c9e29bf1-6331-4c16-d008-db508ccd1e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created save path /content/drive/My Drive/ML project 2/levin/trained_models/unet++\n",
            "Training model with BCEWithLogitsLoss\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch1.pt\n",
            "Epoch 1/10, Training Loss: 0.4876, Validation Loss: 0.3899\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch2.pt\n",
            "Epoch 2/10, Training Loss: 0.2249, Validation Loss: 0.1752\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch3.pt\n",
            "Epoch 3/10, Training Loss: 0.1527, Validation Loss: 0.1528\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch4.pt\n",
            "Epoch 4/10, Training Loss: 0.1218, Validation Loss: 0.1709\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch5.pt\n",
            "Epoch 5/10, Training Loss: 0.1070, Validation Loss: 0.1422\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch6.pt\n",
            "Epoch 6/10, Training Loss: 0.0950, Validation Loss: 0.1445\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch7.pt\n",
            "Epoch 7/10, Training Loss: 0.0987, Validation Loss: 0.1575\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch8.pt\n",
            "Epoch 8/10, Training Loss: 0.0860, Validation Loss: 0.1695\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch9.pt\n",
            "Epoch 9/10, Training Loss: 0.0845, Validation Loss: 0.1733\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch10.pt\n",
            "Epoch 10/10, Training Loss: 0.0779, Validation Loss: 0.2162\n",
            "Training finished\n",
            "Training complete\n",
            "Best epoch: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/ML project 2/levin/train_evaluate.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.model.model.load_state_dict(torch.load(best_model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model loaded from /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch5.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch1.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch2.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch3.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch4.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch6.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch7.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch8.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch9.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/trained_model_epoch10.pt\n",
            "Threshold 0.25, F1: 0.8709, Accuracy: 0.9379, Precision: 0.8751, Recall: 0.8667\n",
            "Threshold 0.5, F1: 0.8571, Accuracy: 0.9445, Precision: 0.8650, Recall: 0.8492\n",
            "Loss plot saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss/loss_over_epochs.png\n",
            "Everything complete. Results saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/BCEWithLogitsLoss.\n",
            "Training model with WeightedBCEWithLogitsLoss\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch1.pt\n",
            "Epoch 1/10, Training Loss: 0.7434, Validation Loss: 0.5534\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch2.pt\n",
            "Epoch 2/10, Training Loss: 0.4331, Validation Loss: 0.3681\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch3.pt\n",
            "Epoch 3/10, Training Loss: 0.3050, Validation Loss: 0.3130\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch4.pt\n",
            "Epoch 4/10, Training Loss: 0.2484, Validation Loss: 0.2957\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch5.pt\n",
            "Epoch 5/10, Training Loss: 0.2057, Validation Loss: 0.3236\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch6.pt\n",
            "Epoch 6/10, Training Loss: 0.1861, Validation Loss: 0.2588\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch7.pt\n",
            "Epoch 7/10, Training Loss: 0.1949, Validation Loss: 0.2710\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch8.pt\n",
            "Epoch 8/10, Training Loss: 0.1668, Validation Loss: 0.3210\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch9.pt\n",
            "Epoch 9/10, Training Loss: 0.1548, Validation Loss: 0.3088\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch10.pt\n",
            "Epoch 10/10, Training Loss: 0.1324, Validation Loss: 0.3114\n",
            "Training finished\n",
            "Training complete\n",
            "Best epoch: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/ML project 2/levin/train_evaluate.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.model.model.load_state_dict(torch.load(best_model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model loaded from /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch6.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch1.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch2.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch3.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch4.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch5.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch7.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch8.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch9.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/trained_model_epoch10.pt\n",
            "Threshold 0.25, F1: 0.8300, Accuracy: 0.9047, Precision: 0.7289, Recall: 0.9635\n",
            "Threshold 0.5, F1: 0.8059, Accuracy: 0.9092, Precision: 0.6934, Recall: 0.9620\n",
            "Loss plot saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss/loss_over_epochs.png\n",
            "Everything complete. Results saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/WeightedBCEWithLogitsLoss.\n",
            "Training model with DiceLoss\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch1.pt\n",
            "Epoch 1/10, Training Loss: 0.5322, Validation Loss: 0.3760\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch2.pt\n",
            "Epoch 2/10, Training Loss: 0.2707, Validation Loss: 0.1921\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch3.pt\n",
            "Epoch 3/10, Training Loss: 0.2044, Validation Loss: 0.2050\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch4.pt\n",
            "Epoch 4/10, Training Loss: 0.1806, Validation Loss: 0.1667\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch5.pt\n",
            "Epoch 5/10, Training Loss: 0.1769, Validation Loss: 0.1880\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch6.pt\n",
            "Epoch 6/10, Training Loss: 0.1677, Validation Loss: 0.2099\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch7.pt\n",
            "Epoch 7/10, Training Loss: 0.1737, Validation Loss: 0.1706\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch8.pt\n",
            "Epoch 8/10, Training Loss: 0.1498, Validation Loss: 0.1569\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch9.pt\n",
            "Epoch 9/10, Training Loss: 0.1281, Validation Loss: 0.1540\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch10.pt\n",
            "Epoch 10/10, Training Loss: 0.1150, Validation Loss: 0.1656\n",
            "Training finished\n",
            "Training complete\n",
            "Best epoch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/ML project 2/levin/train_evaluate.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.model.model.load_state_dict(torch.load(best_model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model loaded from /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch9.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch1.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch2.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch3.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch4.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch5.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch6.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch7.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch8.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/trained_model_epoch10.pt\n",
            "Threshold 0.25, F1: 0.8605, Accuracy: 0.9349, Precision: 0.8911, Recall: 0.8320\n",
            "Threshold 0.5, F1: 0.8460, Accuracy: 0.9421, Precision: 0.8838, Recall: 0.8112\n",
            "Loss plot saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss/loss_over_epochs.png\n",
            "Everything complete. Results saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/DiceLoss.\n",
            "Training model with ComboLoss\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch1.pt\n",
            "Epoch 1/10, Training Loss: 0.5874, Validation Loss: 0.5111\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch2.pt\n",
            "Epoch 2/10, Training Loss: 0.2874, Validation Loss: 0.2145\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch3.pt\n",
            "Epoch 3/10, Training Loss: 0.1983, Validation Loss: 0.2197\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch4.pt\n",
            "Epoch 4/10, Training Loss: 0.1718, Validation Loss: 0.2022\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch5.pt\n",
            "Epoch 5/10, Training Loss: 0.1470, Validation Loss: 0.1613\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch6.pt\n",
            "Epoch 6/10, Training Loss: 0.1374, Validation Loss: 0.1607\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch7.pt\n",
            "Epoch 7/10, Training Loss: 0.1244, Validation Loss: 0.1809\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch8.pt\n",
            "Epoch 8/10, Training Loss: 0.1160, Validation Loss: 0.1634\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch9.pt\n",
            "Epoch 9/10, Training Loss: 0.1017, Validation Loss: 0.1564\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch10.pt\n",
            "Epoch 10/10, Training Loss: 0.0905, Validation Loss: 0.1671\n",
            "Training finished\n",
            "Training complete\n",
            "Best epoch: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/ML project 2/levin/train_evaluate.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.model.model.load_state_dict(torch.load(best_model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model loaded from /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch9.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch1.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch2.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch3.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch4.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch5.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch6.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch7.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch8.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/trained_model_epoch10.pt\n",
            "Threshold 0.25, F1: 0.8767, Accuracy: 0.9410, Precision: 0.8849, Recall: 0.8687\n",
            "Threshold 0.5, F1: 0.8619, Accuracy: 0.9467, Precision: 0.8758, Recall: 0.8485\n",
            "Loss plot saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/loss_over_epochs.png\n",
            "Everything complete. Results saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss.\n",
            "Training model with TverskyLoss\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch1.pt\n",
            "Epoch 1/10, Training Loss: 0.6108, Validation Loss: 0.5032\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch2.pt\n",
            "Epoch 2/10, Training Loss: 0.2787, Validation Loss: 0.1819\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch3.pt\n",
            "Epoch 3/10, Training Loss: 0.2017, Validation Loss: 0.1898\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch4.pt\n",
            "Epoch 4/10, Training Loss: 0.1958, Validation Loss: 0.1655\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch5.pt\n",
            "Epoch 5/10, Training Loss: 0.1526, Validation Loss: 0.1471\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch6.pt\n",
            "Epoch 6/10, Training Loss: 0.1508, Validation Loss: 0.1630\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch7.pt\n",
            "Epoch 7/10, Training Loss: 0.1428, Validation Loss: 0.1566\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch8.pt\n",
            "Epoch 8/10, Training Loss: 0.1249, Validation Loss: 0.1453\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch9.pt\n",
            "Epoch 9/10, Training Loss: 0.1123, Validation Loss: 0.1443\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch10.pt\n",
            "Epoch 10/10, Training Loss: 0.1106, Validation Loss: 0.1387\n",
            "Training finished\n",
            "Training complete\n",
            "Best epoch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/ML project 2/levin/train_evaluate.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.model.model.load_state_dict(torch.load(best_model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model loaded from /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch10.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch1.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch2.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch3.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch4.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch5.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch6.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch7.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch8.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/trained_model_epoch9.pt\n",
            "Threshold 0.25, F1: 0.8437, Accuracy: 0.9310, Precision: 0.9318, Recall: 0.7708\n",
            "Threshold 0.5, F1: 0.8277, Accuracy: 0.9390, Precision: 0.9271, Recall: 0.7476\n",
            "Loss plot saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss/loss_over_epochs.png\n",
            "Everything complete. Results saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/TverskyLoss.\n",
            "Best F1 score: 0.8767475559728146\n",
            "Best threshold: 0.25\n",
            "Best epoch: 9\n",
            "Best loss function: ComboLoss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Free up memory\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "n3MT9L0T-jT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_f1 = 0.876747\n",
        "best_threshold = 0.25\n",
        "best_epoch = 9\n",
        "best_loss_function = ComboLoss()\n",
        "best_data = \"original\""
      ],
      "metadata": {
        "id": "dkbnJCnnGs4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate the model with the best loss function on external data\n",
        "external_save_path = os.path.join(root_path, \"trained_models\", \"unet++\", \"external\")\n",
        "print(\"Created external save path\")\n",
        "os.makedirs(external_save_path, exist_ok=True)\n",
        "model = UnetPlusPlus(encoder_name=encoder_name, encoder_weight=encoder_weight, in_channels=3, num_labels=1)\n",
        "train_eval = TrainAndEvaluate(model, external_train_loader, external_validation_loader, external_test_loader, best_loss_function, 10, external_save_path)\n",
        "f1, threshold, epoch = train_eval.run()\n",
        "if f1 > best_f1:\n",
        "    best_f1 = f1\n",
        "    best_threshold = threshold\n",
        "    best_epoch = epoch\n",
        "    best_data = \"external\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "FTd_Wp0K29Me",
        "outputId": "b52629d7-871a-44ae-e82b-2f7ea1b9c247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created external save path\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-525c226708e6>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnetPlusPlus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainAndEvaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexternal_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexternal_validation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexternal_test_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_loss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexternal_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_f1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbest_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/ML project 2/levin/train_evaluate.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \"\"\"\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training complete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/ML project 2/levin/models/unetpp/unetpp.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataloader, validationloader, criterion, save_path, epochs, learning_rate, save)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mavg_validation_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidationloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_validation_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/ML project 2/levin/models/unetpp/unetpp.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, validationloader, criterion)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidationloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate the model with the best loss function on chicago data\n",
        "chicago_save_path = os.path.join(root_path, \"trained_models\", \"unet++\", \"chicago\")\n",
        "print(\"Created chicago save path\")\n",
        "os.makedirs(chicago_save_path, exist_ok=True)\n",
        "model = UnetPlusPlus(encoder_name=encoder_name, encoder_weight=encoder_weight, in_channels=3, num_labels=1)\n",
        "train_eval = TrainAndEvaluate(model, external_train_loader, external_validation_loader, external_test_loader, best_loss_function, 10, chicago_save_path)\n",
        "f1, threshold, epoch = train_eval.run()\n",
        "if f1 > best_f1:\n",
        "    best_f1 = f1\n",
        "    best_threshold = threshold\n",
        "    best_epoch = epoch\n",
        "    best_data = \"chicago\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFYM2fcf3x3R",
        "outputId": "945d4a2c-d576-4c11-c5c7-501e8a79d29d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created chicago save path\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch1.pt\n",
            "Epoch 1/10, Training Loss: 0.3669, Validation Loss: 0.2606\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch2.pt\n",
            "Epoch 2/10, Training Loss: 0.2535, Validation Loss: 0.2446\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch3.pt\n",
            "Epoch 3/10, Training Loss: 0.2244, Validation Loss: 0.2256\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch4.pt\n",
            "Epoch 4/10, Training Loss: 0.2133, Validation Loss: 0.2287\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch5.pt\n",
            "Epoch 5/10, Training Loss: 0.1982, Validation Loss: 0.2161\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch6.pt\n",
            "Epoch 6/10, Training Loss: 0.1856, Validation Loss: 0.2127\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch7.pt\n",
            "Epoch 7/10, Training Loss: 0.1758, Validation Loss: 0.2314\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch8.pt\n",
            "Epoch 8/10, Training Loss: 0.1698, Validation Loss: 0.2094\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch9.pt\n",
            "Epoch 9/10, Training Loss: 0.1554, Validation Loss: 0.2058\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch10.pt\n",
            "Epoch 10/10, Training Loss: 0.1447, Validation Loss: 0.2047\n",
            "Training finished\n",
            "Training complete\n",
            "Best epoch: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/ML project 2/levin/train_evaluate.py:186: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.model.model.load_state_dict(torch.load(best_model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model loaded from /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch10.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch1.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch2.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch3.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch4.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch5.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch6.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch7.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch8.pt\n",
            "Deleted model: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/trained_model_epoch9.pt\n",
            "Threshold 0.25, F1: 0.8601, Accuracy: 0.9377, Precision: 0.8596, Recall: 0.8606\n",
            "Threshold 0.5, F1: 0.8294, Accuracy: 0.9510, Precision: 0.8095, Recall: 0.8504\n",
            "Loss plot saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss/loss_over_epochs.png\n",
            "Everything complete. Results saved to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/chicago/ComboLoss.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nJ7YPEZPKz9C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}