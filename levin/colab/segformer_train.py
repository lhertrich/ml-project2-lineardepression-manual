# -*- coding: utf-8 -*-
"""segformer_train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QwrCyiT8XrDM_RDyFxSDN2_7hxb7PNKI
"""

from google.colab import drive
drive.mount('/content/drive')

import sys

project_path = '/content/drive/My Drive/ML project 2/'
sys.path.append(project_path)

import torchvision.transforms as T
import torchvision.transforms.functional as TF
import os
import torch
import numpy as np
import json
import matplotlib.pyplot as plt
import gc

from levin.SegFormer.segformer_b3 import SegFormer
from levin.dataset import RoadSegmentationDataset
from torch.utils.data import DataLoader
from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
from transformers import SegformerImageProcessor
from torchvision.transforms.functional import InterpolationMode
from datetime import datetime

class DiceLoss(torch.nn.Module):
  def __init__(self, epsilon=1e-6):
    super(DiceLoss, self).__init__()
    self.epsilon = epsilon

  def forward(self, logits, targets):
    probs = torch.sigmoid(logits)  # Apply sigmoid to get probabilities
    num = 2 * (probs * targets).sum(dim=(2, 3)) + self.epsilon
    den = probs.sum(dim=(2, 3)) + targets.sum(dim=(2, 3)) + self.epsilon
    dice_loss = 1 - (num / den)
    return dice_loss.mean()

class ComboLoss(torch.nn.Module):
  def __init__(self, weight=0.5, epsilon=1e-6):
    super(ComboLoss, self).__init__()
    self.weight = weight
    self.epsilon = epsilon
    self.bce = torch.nn.BCEWithLogitsLoss()

  def forward(self, logits, targets):
    # BCE Loss
    bce_loss = self.bce(logits, targets)

    # Dice Loss
    probs = torch.sigmoid(logits)
    num = 2 * (probs * targets).sum(dim=(2, 3)) + self.epsilon
    den = probs.sum(dim=(2, 3)) + targets.sum(dim=(2, 3)) + self.epsilon
    dice_loss = 1 - (num / den).mean()

    return self.weight * bce_loss + (1 - self.weight) * dice_loss

class TverskyLoss(torch.nn.Module):
  def __init__(self, alpha=0.7, beta=0.3, epsilon=1e-6):
    super(TverskyLoss, self).__init__()
    self.alpha = alpha
    self.beta = beta
    self.epsilon = epsilon

  def forward(self, logits, targets):
    probs = torch.sigmoid(logits)
    tp = (probs * targets).sum(dim=(2, 3))
    fp = ((1 - targets) * probs).sum(dim=(2, 3))
    fn = (targets * (1 - probs)).sum(dim=(2, 3))
    tversky = (tp + self.epsilon) / (tp + self.alpha * fp + self.beta * fn + self.epsilon)
    return 1 - tversky.mean()

class WeightedBCEWithLogitsLoss(torch.nn.Module):
  def __init__(self, pos_weight=4.0):
    super(WeightedBCEWithLogitsLoss, self).__init__()
    self.loss = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))

  def forward(self, logits, targets):
    return self.loss(logits, targets)

def patch_to_label(patch, threshold=0.5):
    """
    Assign a label to a patch based on the average pixel intensity.
    :param patch: 16x16 patch of the predicted mask.
    :param threshold: Foreground threshold for binary classification.
    :return: Binary label (0 or 1).
    """
    mean_value = np.mean(patch)
    if np.isnan(mean_value):
        print(f"Encountered NaN in patch mean: {patch}")
    if patch.size == 0:
        print("Encountered empty patch!")
    return 1 if mean_value > threshold else 0

def evaluate_model(model, dataloader, device, patch_size=16, threshold=0.5):
    all_preds = []
    all_targets = []

    with torch.no_grad():
        for images, masks in dataloader:
            # Move images and masks to the correct device
            images = images.to(device)
            masks = masks.cpu().numpy()

            # Get predictions for the entire batch
            preds = model.predict(images)
            preds = preds.cpu().numpy()

            for pred, mask in zip(preds, masks):
              pred = np.squeeze(pred)  # Remove the singleton dimension
              mask = np.squeeze(mask)

              if pred.shape != mask.shape:
                raise ValueError(f"Shape mismatch: pred {pred.shape}, mask {mask.shape}")

              # Divide prediction and mask into patches
              height, width = mask.shape
              patch_preds = []
              patch_targets = []

              for y in range(0, height, patch_size):
                  for x in range(0, width, patch_size):
                      pred_patch = pred[y:min(y+patch_size, height), x:min(x+patch_size, width)]
                      mask_patch = mask[y:min(y+patch_size, height), x:min(x+patch_size, width)]

                      if pred_patch.size == 0 or mask_patch.size == 0:
                        print(f"Skipping empty patch at y={y}, x={x}")
                        continue

                      # Convert patch to binary label
                      pred_label = patch_to_label(pred_patch, threshold)
                      target_label = patch_to_label(mask_patch, threshold)

                      patch_preds.append(pred_label)
                      patch_targets.append(target_label)

              all_preds.extend(patch_preds)
              all_targets.extend(patch_targets)

    if not all_preds or not all_targets:
        raise ValueError("Predictions or targets are empty. Evaluation cannot proceed.")
    # Calculate F1 score at the patch level
    f1 = f1_score(all_targets, all_preds, average="binary")

    # Calculate accuracy at the patch level
    accuracy = accuracy_score(all_targets, all_preds)

    precision = precision_score(all_targets, all_preds, average="binary")
    recall = recall_score(all_targets, all_preds, average="binary")
    return f1, accuracy, precision, recall

def plot_losses(train_losses, val_losses, save_dir):
    """
    Plot and save training and validation losses.

    :param train_losses: Dictionary of epoch-wise training losses
    :param val_losses: Dictionary of epoch-wise validation losses
    :param save_dir: Directory to save the plot
    """
    # Extract epochs and losses
    epochs = list(train_losses.keys())
    train_loss_values = list(train_losses.values())
    val_loss_values = list(val_losses.values())

    # Create the plot
    plt.figure(figsize=(10, 6))
    plt.plot(epochs, train_loss_values, label="Training Loss", marker='o')
    plt.plot(epochs, val_loss_values, label="Validation Loss", marker='x')
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Training and Validation Loss Over Epochs")
    plt.legend()
    plt.grid()
    plt.tight_layout()

    # Save the plot
    plot_path = os.path.join(save_dir, "loss_over_epochs.png")
    plt.savefig(plot_path)
    plt.close()

    print(f"Loss plot saved to {plot_path}")

def save_predictions(model, test_loader, save_dir, device, num_images=5):
    predictions_dir = os.path.join(save_dir, "predictions")
    os.makedirs(predictions_dir, exist_ok=True)

    with torch.no_grad():
        for i, (images, masks) in enumerate(test_loader):
            if i >= num_images:
                break

            # Move to device
            images = images.to(device)
            masks = masks.cpu().numpy()

            # Get predictions
            preds = model.predict(images).cpu().numpy()
            unique_values, counts = np.unique(preds, return_counts=True)


            for idx in range(len(images)):
                image = images[idx].cpu().squeeze()
                maski = masks[idx].squeeze().squeeze()
                predi = preds[idx].squeeze().squeeze()
                # Save input image, ground truth mask, and predicted mask
                img = TF.to_pil_image(image)
                mask = TF.to_pil_image((maski * 255).astype(np.uint8))
                pred = TF.to_pil_image((predi * 255).astype(np.uint8))

                img.save(os.path.join(predictions_dir, f"test_image_{i*len(images)+idx}.png"))
                mask.save(os.path.join(predictions_dir, f"test_mask_{i*len(images)+idx}.png"))
                pred.save(os.path.join(predictions_dir, f"pred_mask_{i*len(images)+idx}.png"))

def train_and_evaluate_model(model, train_loader, validation_loader, test_loader, criterion, epochs, save_dir, device):
    # Create a unique folder for this run
    model_dir = os.path.join(save_dir, f"{criterion}")
    os.makedirs(model_dir, exist_ok=True)

    # Initialize logs
    evaluation_metrics = {}

    model_path = os.path.join(model_dir, "segformer.pt")
    model.train(train_loader, validation_loader, criterion, epochs=epochs, save_path=model_path)
    print("Training complete")

    # Evaluate the model on the test set for different thresholds
    thresholds = [0.25, 0.5, 0.75]
    evaluation_metrics["thresholds"] = {}
    best_f1 = 0
    best_threshold = 0
    for threshold in thresholds:
        f1, acc, prec, rec = evaluate_model(model, test_loader, device, threshold=threshold)
        if f1 > best_f1:
            best_f1 = f1
            best_threshold = threshold
        evaluation_metrics["thresholds"][f"{threshold:.2f}"] = {"f1_score": f1, "accuracy": acc, "precision": prec, "recall": rec}
        print(f"Threshold {threshold}, F1: {f1:.4f}, Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}")

    # Save evaluation metrics to JSON
    metrics_path = os.path.join(model_dir, "evaluation_metrics.json")
    with open(metrics_path, "w") as f:
        json.dump(evaluation_metrics, f, indent=4)

    plot_losses(model.losses, model.validation_losses, model_dir)
    best_epoch = min(model.validation_losses, key=model.validation_losses.get)
    print(f"Best epoch: {best_epoch}")

    # Save predictions for 5 test images
    save_predictions(model, test_loader, model_dir, device)

    print(f"Everything complete. Results saved to {model_dir}.")
    return best_f1, best_threshold, best_epoch

# Construct the absolute path to the data folder
image_dir = os.path.join(project_path, "data", "training", "augmented", "images")
mask_dir = os.path.join(project_path, "data", "training", "augmented", "masks")

print(f"Image directory: {image_dir}")
print(f"Mask directory: {mask_dir}")

# Check if the paths exist
if not os.path.exists(image_dir):
    raise FileNotFoundError(f"Image directory not found: {image_dir}")
if not os.path.exists(mask_dir):
    raise FileNotFoundError(f"Mask directory not found: {mask_dir}")

# Define transforms for images and masks
feature_extractor = SegformerImageProcessor(
    do_normalize=True,
    do_resize=True,
    size=512
)

mask_transform = T.Compose([
    T.Resize((512, 512), interpolation=InterpolationMode.NEAREST),  # Use nearest-neighbor
    T.ToTensor()
])

image_filenames = sorted(os.listdir(image_dir))
mask_filenames = sorted(os.listdir(mask_dir))

# Split filenames into train and test sets
train_images, test_images, train_masks, test_masks = train_test_split(
    image_filenames, mask_filenames, test_size=0.2, random_state=42
)

train_images, validation_images, train_masks, validation_masks = train_test_split(
    train_images, train_masks, test_size=0.1, random_state=42
)
print(f"Number of training images: {len(train_images)}")
print(f"Number of validation images: {len(validation_images)}")
print(f"Number of test images: {len(test_images)}")

# Define datasets for train and test sets
train_dataset = RoadSegmentationDataset(image_dir, mask_dir, train_images, train_masks, feature_extractor, mask_transform)
test_dataset = RoadSegmentationDataset(image_dir, mask_dir, test_images, test_masks, feature_extractor, mask_transform)
validation_dataset = RoadSegmentationDataset(image_dir, mask_dir, validation_images, validation_masks, feature_extractor, mask_transform)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)
validation_loader = DataLoader(validation_dataset, batch_size=8, shuffle=False, num_workers=2)

# Test different loss functions
save_path = os.path.join(project_path, "levin", "trained_models", "segformer_b3")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
loss_functions = [torch.nn.BCEWithLogitsLoss(), WeightedBCEWithLogitsLoss(), DiceLoss(), ComboLoss(), TverskyLoss()]
best_f1 = 0
best_threshold = 0
best_epoch = 0
best_loss_function = None
for criterion in loss_functions:
  print(f"Training model with {criterion.__class__.__name__}")
  model = SegFormer()
  # Train and evaluate
  f1, threshold, epoch = train_and_evaluate_model(model, train_loader, validation_loader, test_loader, criterion, epochs=20, save_dir=save_path, device=device)
  if f1 > best_f1:
    best_f1 = f1
    best_threshold = threshold
    best_epoch = epoch
    best_loss_function = criterion

  # Free up memory
  del model
  gc.collect()
  torch.cuda.empty_cache()

print(f"Best F1 score: {best_f1}")
print(f"Best threshold: {best_threshold}")
print(f"Best epoch: {best_epoch}")
print(f"Best loss function: {best_loss_function.__class__.__name__}")

# Dice loss did not overfit within 10 epochs, train and evaluate again with 20 epochs
criterion = DiceLoss()
model = SegFormer()
f1, threshold, epoch = train_and_evaluate_model(model, train_loader, validation_loader, test_loader, criterion, epochs=20, save_dir=save_path, device=device)

