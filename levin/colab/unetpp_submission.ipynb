{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOIhx4ysRFDe",
        "outputId": "df3b6e19-77ac-4736-e6f0-62349c1d819f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "lxWZOqz-RKq7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_path = '/content/drive/My Drive/ML project 2/'\n",
        "module_path = \"/content/drive/My Drive/ML project 2/levin\"\n",
        "sys.path.append(module_path)\n",
        "sys.path.append(project_path)"
      ],
      "metadata": {
        "id": "_TlDmV4-RM41"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U segmentation-models-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l_CnJZLRQFS",
        "outputId": "4fc62151-d48a-4171-f013-356280914297"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: segmentation-models-pytorch in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.7.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.6 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.26.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (11.0.0)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.7.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (1.17.0)\n",
            "Requirement already satisfied: timm==0.9.7 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.9.7)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.5.1+cu121)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (4.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.26.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torchvision.transforms as T\n",
        "import torch\n",
        "import json\n",
        "from levin.train_evaluate import TrainAndEvaluate\n",
        "from levin.models.unetpp.unetpp_dataset_submission import UnetPlusPlusRoadSegmentationDatasetSubmission\n",
        "from levin.models.unetpp.unetpp import UnetPlusPlus\n",
        "from levin.loss_functions import ComboLoss, DiceLoss, TverskyLoss, WeightedBCEWithLogitsLoss\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from levin import helpers\n",
        "from levin.create_submission import CreateSubmission\n",
        "from levin.helpers import get_test_images"
      ],
      "metadata": {
        "id": "7GA_gfh-RSAO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_name=\"resnet50\"\n",
        "encoder_weight=\"imagenet\""
      ],
      "metadata": {
        "id": "Ys0IO_XeXGPq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = os.path.join(project_path, \"data\", \"test_set_images\")"
      ],
      "metadata": {
        "id": "JwoKbTyeRci7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.join(module_path, \"trained_models\", \"unet++\", \"ComboLoss\", \"trained_model_epoch9.pt\")"
      ],
      "metadata": {
        "id": "_JcsBcM7Scel"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = get_test_images(image_dir)\n",
        "test_images.sort(key=lambda x: int(os.path.basename(x).split('_')[1].split('.')[0]))\n",
        "test_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsNh3jMIWFrA",
        "outputId": "4903b692-4e2a-4021-d3f3-f117c8012785"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/ML project 2/data/test_set_images/test_1/test_1.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_2/test_2.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_3/test_3.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_4/test_4.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_5/test_5.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_6/test_6.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_7/test_7.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_8/test_8.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_9/test_9.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_10/test_10.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_11/test_11.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_12/test_12.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_13/test_13.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_14/test_14.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_15/test_15.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_16/test_16.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_17/test_17.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_18/test_18.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_19/test_19.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_20/test_20.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_21/test_21.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_22/test_22.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_23/test_23.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_24/test_24.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_25/test_25.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_26/test_26.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_27/test_27.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_28/test_28.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_29/test_29.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_30/test_30.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_31/test_31.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_32/test_32.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_33/test_33.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_34/test_34.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_35/test_35.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_36/test_36.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_37/test_37.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_38/test_38.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_39/test_39.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_40/test_40.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_41/test_41.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_42/test_42.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_43/test_43.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_44/test_44.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_45/test_45.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_46/test_46.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_47/test_47.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_48/test_48.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_49/test_49.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_50/test_50.png']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = UnetPlusPlusRoadSegmentationDatasetSubmission(image_dir, test_images, encoder_name, encoder_weight)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "V7SvdOM1k-LU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UnetPlusPlus(encoder_name=encoder_name, encoder_weight=encoder_weight, in_channels=3, num_labels=1)\n",
        "model.model.load_state_dict(torch.load(model_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dI4CiUJXl2V",
        "outputId": "fcfef2d7-0b73-46be-e4ef-ef8eed47b0d3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-1b64d787c653>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2hHzsPaX0s4",
        "outputId": "1e4a11e9-6cca-4842-d840-5fa40a1ebda4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission_path = os.path.join(module_path, \"trained_models\", \"unet++\", \"ComboLoss\", \"submission\")\n",
        "create_sub = CreateSubmission(model, test_dataloader, 0.25, submission_path, device)"
      ],
      "metadata": {
        "id": "HCPGzrNuYLdp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_sub.create_and_save_predictions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqHWT-9QYoih",
        "outputId": "6bff7e75-e21f-47d9-82ec-41a8daf7e99e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving prediction:  1\n",
            "Saving prediction:  2\n",
            "Saving prediction:  3\n",
            "Saving prediction:  4\n",
            "Saving prediction:  5\n",
            "Saving prediction:  6\n",
            "Saving prediction:  7\n",
            "Saving prediction:  8\n",
            "Saving prediction:  9\n",
            "Saving prediction:  10\n",
            "Saving prediction:  11\n",
            "Saving prediction:  12\n",
            "Saving prediction:  13\n",
            "Saving prediction:  14\n",
            "Saving prediction:  15\n",
            "Saving prediction:  16\n",
            "Saving prediction:  17\n",
            "Saving prediction:  18\n",
            "Saving prediction:  19\n",
            "Saving prediction:  20\n",
            "Saving prediction:  21\n",
            "Saving prediction:  22\n",
            "Saving prediction:  23\n",
            "Saving prediction:  24\n",
            "Saving prediction:  25\n",
            "Saving prediction:  26\n",
            "Saving prediction:  27\n",
            "Saving prediction:  28\n",
            "Saving prediction:  29\n",
            "Saving prediction:  30\n",
            "Saving prediction:  31\n",
            "Saving prediction:  32\n",
            "Saving prediction:  33\n",
            "Saving prediction:  34\n",
            "Saving prediction:  35\n",
            "Saving prediction:  36\n",
            "Saving prediction:  37\n",
            "Saving prediction:  38\n",
            "Saving prediction:  39\n",
            "Saving prediction:  40\n",
            "Saving prediction:  41\n",
            "Saving prediction:  42\n",
            "Saving prediction:  43\n",
            "Saving prediction:  44\n",
            "Saving prediction:  45\n",
            "Saving prediction:  46\n",
            "Saving prediction:  47\n",
            "Saving prediction:  48\n",
            "Saving prediction:  49\n",
            "Saving prediction:  50\n",
            "Saved 51 predictions to /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_path = os.path.join(submission_path, \"prediction\", \"predictions\")\n",
        "mask_filenames = os.listdir(mask_path)\n",
        "mask_filenames = [os.path.join(mask_path, f) for f in mask_filenames]\n",
        "mask_filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-jGoNFkYta3",
        "outputId": "4617d38e-1647-4e83-b28e-11102e314228"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_1.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_2.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_3.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_4.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_5.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_6.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_7.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_8.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_9.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_10.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_11.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_12.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_13.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_14.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_15.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_16.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_17.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_18.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_19.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_20.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_21.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_22.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_23.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_24.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_25.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_26.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_27.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_28.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_29.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_30.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_31.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_32.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_33.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_34.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_35.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_36.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_37.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_38.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_39.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_40.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_41.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_42.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_43.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_44.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_45.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_46.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_47.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_48.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_49.png',\n",
              " '/content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_50.png']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission_name = os.path.join(submission_path, \"submission.csv\")\n",
        "create_sub.masks_to_submission(submission_name, *mask_filenames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCJ87OoyiHbL",
        "outputId": "531dfbfa-711b-4092-8b07-c1fee83a5697"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_1.png, number: 1\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_2.png, number: 2\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_3.png, number: 3\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_4.png, number: 4\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_5.png, number: 5\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_6.png, number: 6\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_7.png, number: 7\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_8.png, number: 8\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_9.png, number: 9\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_10.png, number: 10\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_11.png, number: 11\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_12.png, number: 12\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_13.png, number: 13\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_14.png, number: 14\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_15.png, number: 15\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_16.png, number: 16\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_17.png, number: 17\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_18.png, number: 18\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_19.png, number: 19\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_20.png, number: 20\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_21.png, number: 21\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_22.png, number: 22\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_23.png, number: 23\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_24.png, number: 24\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_25.png, number: 25\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_26.png, number: 26\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_27.png, number: 27\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_28.png, number: 28\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_29.png, number: 29\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_30.png, number: 30\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_31.png, number: 31\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_32.png, number: 32\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_33.png, number: 33\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_34.png, number: 34\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_35.png, number: 35\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_36.png, number: 36\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_37.png, number: 37\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_38.png, number: 38\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_39.png, number: 39\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_40.png, number: 40\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_41.png, number: 41\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_42.png, number: 42\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_43.png, number: 43\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_44.png, number: 44\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_45.png, number: 45\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_46.png, number: 46\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_47.png, number: 47\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_48.png, number: 48\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_49.png, number: 49\n",
            "Filename: /content/drive/My Drive/ML project 2/levin/trained_models/unet++/ComboLoss/submission/prediction/predictions/prediction_50.png, number: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KrPpJVm0cdUG"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}