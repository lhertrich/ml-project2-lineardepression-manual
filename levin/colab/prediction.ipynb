{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtzlXWCIlEnn",
        "outputId": "65c8c882-af12-4049-9376-d8c48260c045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/My Drive/ML project 2/levin/trained_models/segformer_raw.pt\""
      ],
      "metadata": {
        "id": "4a1uTV70lG9Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/ML project 2/levin')"
      ],
      "metadata": {
        "id": "dSRpr_3KmnQl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from SegFormer.segformer import SegFormer\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.image as mpimg\n",
        "import shutil"
      ],
      "metadata": {
        "id": "7uQ-ANYyobuA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SegFormer()\n",
        "\n",
        "# Load the saved state dictionary\n",
        "model.model.load_state_dict(torch.load(model_path, map_location=model.device))\n",
        "model.model.to(model.device)\n",
        "\n",
        "print(\"Model loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP04G20gmu9k",
        "outputId": "db796fc1-2442-47be-e973-e93c1f662b04"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([1, 256, 1, 1]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-5-7f623bda2926>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.model.load_state_dict(torch.load(model_path, map_location=model.device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get paths for test images\n",
        "def get_test_images(test_folder):\n",
        "    \"\"\"\n",
        "    Recursively retrieve all test image file paths from the test folder.\n",
        "    :param test_folder: Path to the folder containing test images in subfolders.\n",
        "    :return: List of file paths to test images.\n",
        "    \"\"\"\n",
        "    image_paths = []\n",
        "    for root, _, files in os.walk(test_folder):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                image_paths.append(os.path.join(root, file))\n",
        "    return image_paths"
      ],
      "metadata": {
        "id": "zPiomV-am1qk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = get_test_images(\"/content/drive/My Drive/ML project 2/data/test_set_images\")\n",
        "paths.sort(key=lambda x: int(os.path.basename(x).split('_')[1].split('.')[0]))\n",
        "paths"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1g2-lT436p8",
        "outputId": "616759e8-018f-4526-caf3-e63cbd210a54"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/ML project 2/data/test_set_images/test_1/test_1.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_2/test_2.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_3/test_3.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_4/test_4.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_5/test_5.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_6/test_6.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_7/test_7.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_8/test_8.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_9/test_9.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_10/test_10.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_11/test_11.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_12/test_12.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_13/test_13.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_14/test_14.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_15/test_15.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_16/test_16.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_17/test_17.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_18/test_18.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_19/test_19.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_20/test_20.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_21/test_21.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_22/test_22.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_23/test_23.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_24/test_24.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_25/test_25.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_26/test_26.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_27/test_27.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_28/test_28.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_29/test_29.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_30/test_30.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_31/test_31.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_32/test_32.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_33/test_33.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_34/test_34.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_35/test_35.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_36/test_36.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_37/test_37.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_38/test_38.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_39/test_39.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_40/test_40.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_41/test_41.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_42/test_42.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_43/test_43.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_44/test_44.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_45/test_45.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_46/test_46.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_47/test_47.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_48/test_48.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_49/test_49.png',\n",
              " '/content/drive/My Drive/ML project 2/data/test_set_images/test_50/test_50.png']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_predictions_as_images(image_paths, model, output_folder):\n",
        "    \"\"\"\n",
        "    Save predicted masks as images in the output folder.\n",
        "    :param image_paths: List of test image file paths.\n",
        "    :param model: SegFormer model for prediction.\n",
        "    :param output_folder: Path to save predicted masks.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for idx, image_path in enumerate(image_paths, start=1):\n",
        "        # Load and predict mask\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        predicted_mask = model.predict(image)  # Shape: [height, width]\n",
        "\n",
        "        # Save mask as an image\n",
        "        output_path = os.path.join(output_folder, f\"mask_{idx:03d}.png\")\n",
        "        Image.fromarray((predicted_mask * 255).astype(np.uint8)).save(output_path)\n",
        "\n",
        "    print(f\"Predicted masks saved to {output_folder}\")"
      ],
      "metadata": {
        "id": "GU-vkMfzoPg0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foreground_threshold = 0.25  # Threshold for patch classification\n",
        "\n",
        "# Assign a label to a patch based on the foreground threshold\n",
        "def patch_to_label(patch):\n",
        "    df = np.mean(patch)\n",
        "    if df > foreground_threshold:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Generate submission strings from a single mask image\n",
        "def mask_to_submission_strings(image_filename, img_number):\n",
        "    \"\"\"\n",
        "    Reads a single mask image and outputs the strings for the submission file.\n",
        "    :param image_filename: Path to the mask image file.\n",
        "    :param img_number: Image number (used in the submission ID).\n",
        "    :yield: Submission strings for each 16x16 patch.\n",
        "    \"\"\"\n",
        "    im = mpimg.imread(image_filename)\n",
        "    print(f\"Image size: {im.shape}\")\n",
        "    patch_size = 16\n",
        "    height, width = im.shape[:2]\n",
        "\n",
        "    # Iterate over the full image resolution\n",
        "    for y in range(0, height, patch_size):\n",
        "        for x in range(0, width, patch_size):\n",
        "            patch = im[y:y + patch_size, x:x + patch_size]\n",
        "            label = patch_to_label(patch)\n",
        "            yield(\"{:03d}_{}_{},\".format(img_number, y, x) + str(label))\n",
        "\n",
        "# Convert all masks into a single submission file\n",
        "def masks_to_submission(submission_filename, image_filenames):\n",
        "    \"\"\"\n",
        "    Converts predicted masks into a submission file.\n",
        "    :param submission_filename: Path to save the submission file.\n",
        "    :param image_filenames: List of mask image file paths.\n",
        "    \"\"\"\n",
        "    with open(submission_filename, 'w') as f:\n",
        "        f.write('id,prediction\\n')  # Write header\n",
        "        for img_number, image_filename in enumerate(image_filenames, start=1):\n",
        "            f.writelines('{}\\n'.format(s) for s in mask_to_submission_strings(image_filename, img_number))"
      ],
      "metadata": {
        "id": "wIjYWoVOr4U6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_test_image(image_path, target_size=(512, 512)):\n",
        "    \"\"\"\n",
        "    Preprocess a test image to match the model's input size.\n",
        "    \"\"\"\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = image.resize(target_size, Image.BILINEAR)\n",
        "    return image\n",
        "\n",
        "\n",
        "def postprocess_prediction(predicted_mask, original_size=(608, 608)):\n",
        "    \"\"\"\n",
        "    Resize the model's predicted mask back to the original image size.\n",
        "    \"\"\"\n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "\n",
        "    mask_image = Image.fromarray((predicted_mask * 255).astype(np.uint8))  # Convert to image for resizing\n",
        "    mask_image = mask_image.resize(original_size, Image.NEAREST)  # Resize back to 608x608\n",
        "    return np.array(mask_image) // 255  # Convert back to binary mask"
      ],
      "metadata": {
        "id": "R51wnu5p1A-q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "test_images_folder = \"/content/drive/My Drive/ML project 2/data/test_set_images\"\n",
        "output_masks_folder = \"/content/drive/My Drive/ML project 2/levin/predictions\"\n",
        "submission_file = \"/content/drive/My Drive/ML project 2/levin/segformer_raw_submission.csv\"\n",
        "\n",
        "# Clear predictions folder\n",
        "if os.path.exists(output_masks_folder):\n",
        "    shutil.rmtree(output_masks_folder)\n",
        "os.makedirs(output_masks_folder, exist_ok=True)\n",
        "\n",
        "# Retrieve and sort test image paths (simplified sorting)\n",
        "test_image_paths = get_test_images(test_images_folder)\n",
        "test_image_paths.sort(key=lambda x: int(os.path.basename(x).split('_')[1].split('.')[0]))\n",
        "\n",
        "# Process each test image\n",
        "for idx, image_path in enumerate(test_image_paths, start=1):\n",
        "    test_image = preprocess_test_image(image_path)  # Resize to 512x512\n",
        "    predicted_mask = model.predict(test_image)      # Predict (512x512)\n",
        "    resized_mask = postprocess_prediction(predicted_mask, original_size=(608, 608))  # Resize back to 608x608\n",
        "\n",
        "    # Save resized mask\n",
        "    mask_path = os.path.join(output_masks_folder, f\"mask_{idx:03d}.png\")\n",
        "    Image.fromarray((resized_mask * 255).astype(np.uint8)).save(mask_path)\n",
        "\n",
        "# Generate submission file\n",
        "predicted_mask_paths = sorted([os.path.join(output_masks_folder, f) for f in os.listdir(output_masks_folder)], key=lambda x: int(os.path.basename(x).split('_')[1].split('.')[0]))\n",
        "masks_to_submission(submission_file, predicted_mask_paths)\n",
        "\n",
        "print(f\"Submission file created at {submission_file}\")\n",
        "\n",
        "# Validate row count\n",
        "with open(submission_file, \"r\") as f:\n",
        "    rows = f.readlines()\n",
        "print(f\"Total rows (excluding header): {len(rows) - 1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8trETe3opdk",
        "outputId": "ed677fca-3983-483e-a09d-eb8dd3fb2f49"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Image size: (608, 608)\n",
            "Submission file created at /content/drive/My Drive/ML project 2/levin/segformer_raw_submission.csv\n",
            "Total rows (excluding header): 72200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ja18r_qO0Fsa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}