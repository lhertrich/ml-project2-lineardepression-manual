{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-3evBxDI4XD",
        "outputId": "b377efd8-31e3-4bdd-9dc0-e050754c2350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys"
      ],
      "metadata": {
        "id": "WvZNPTIrJV3D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "project_path = '/content/drive/My Drive/ML project 2/'\n",
        "sys.path.append(project_path)"
      ],
      "metadata": {
        "id": "X1zyUrNJI8iN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from levin.SegFormer.segformer import SegFormer\n",
        "from levin.road_data import RoadSegmentationDataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as T\n",
        "import os\n",
        "import torch"
      ],
      "metadata": {
        "id": "JE7tHzW7JToQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the absolute path to the data folder\n",
        "image_dir = os.path.join(project_path, \"data\", \"training\", \"augmented\", \"images\")\n",
        "mask_dir = os.path.join(project_path, \"data\", \"training\", \"augmented\", \"masks\")\n",
        "\n",
        "print(f\"Image directory: {image_dir}\")\n",
        "print(f\"Mask directory: {mask_dir}\")\n",
        "\n",
        "# Check if the paths exist\n",
        "if not os.path.exists(image_dir):\n",
        "    raise FileNotFoundError(f\"Image directory not found: {image_dir}\")\n",
        "if not os.path.exists(mask_dir):\n",
        "    raise FileNotFoundError(f\"Mask directory not found: {mask_dir}\")\n",
        "\n",
        "# Define transforms for images and masks\n",
        "image_transform = T.Compose([\n",
        "    T.Resize((512, 512)),  # Resize images to 512x512\n",
        "    T.ToTensor(),          # Convert to PyTorch tensor\n",
        "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "mask_transform = T.Compose([\n",
        "    T.Resize((512, 512)),  # Resize masks to 512x512\n",
        "    T.ToTensor()           # Convert to PyTorch tensor (binary mask stays as float)\n",
        "])\n",
        "\n",
        "image_filenames = sorted(os.listdir(image_dir))\n",
        "mask_filenames = sorted(os.listdir(mask_dir))\n",
        "\n",
        "# Split filenames into train and test sets\n",
        "#train_images, test_images, train_masks, test_masks = train_test_split(\n",
        "#    image_filenames, mask_filenames, test_size=0.2, random_state=42\n",
        "#)\n",
        "\n",
        "# Define datasets for train and test sets\n",
        "train_dataset = RoadSegmentationDataset(\n",
        "    image_dir=image_dir,\n",
        "    mask_dir=mask_dir,\n",
        "    transform=image_transform,\n",
        "    target_transform=mask_transform\n",
        ")\n",
        "\n",
        "# test_dataset = RoadSegmentationDataset(\n",
        "#     image_dir=image_dir,\n",
        "#     mask_dir=mask_dir,\n",
        "#     transform=image_transform,\n",
        "#     target_transform=mask_transform\n",
        "# )\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
        "\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "save_path = os.path.join(project_path, \"levin\", \"trained_models\", \"segformer_raw.pt\")\n",
        "model = SegFormer()\n",
        "model.train(train_loader, criterion, epochs=10, save_path=save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E32bkMWJds-",
        "outputId": "12676f1c-e2a0-4f31-c806-02f54d6b3e49"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image directory: /content/drive/My Drive/ML project 2/data/training/augmented/images\n",
            "Mask directory: /content/drive/My Drive/ML project 2/data/training/augmented/masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/segformer-b0-finetuned-ade-512-512 and are newly initialized because the shapes did not match:\n",
            "- decode_head.classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
            "- decode_head.classifier.weight: found shape torch.Size([150, 256, 1, 1]) in the checkpoint and torch.Size([1, 256, 1, 1]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.5021\n",
            "Epoch 2/10, Loss: 0.2935\n",
            "Epoch 3/10, Loss: 0.2223\n",
            "Epoch 4/10, Loss: 0.1881\n",
            "Epoch 5/10, Loss: 0.1672\n",
            "Epoch 6/10, Loss: 0.1519\n",
            "Epoch 7/10, Loss: 0.1414\n",
            "Epoch 8/10, Loss: 0.1345\n",
            "Epoch 9/10, Loss: 0.1258\n",
            "Epoch 10/10, Loss: 0.1202\n",
            "Model saved to /content/drive/My Drive/ML project 2/levin/trained_models/segformer_raw.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fj8RjhlQKbnk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}